# #!/usr/bin/env python3
# import os
# import random
# import torch
# import torch.nn.functional as F
# from torch.utils.data import DataLoader
# from torchvision.utils import save_image
# from tqdm import tqdm
# from PIL import Image
# import numpy as np
# from safetensors.torch import load_file  # âœ… safetensors å¯¼å…¥
# from dataset.sky import SkyDataset
# from pi3.models.pi3 import Pi3
#
# # ==============================
# # å¯è§†åŒ–å‡½æ•°
# # ==============================
# def visualize_results(img, pred_mask, gt_mask, save_path):
#     """ä¿å­˜è¾“å…¥å›¾ã€é¢„æµ‹ç»“æœã€GTåˆ°ä¸€å¼ å›¾ä¸­"""
#     os.makedirs(os.path.dirname(save_path), exist_ok=True)
#     img = (img.cpu().permute(1, 2, 0).numpy() * 255).astype(np.uint8)
#     pred_mask = (pred_mask.squeeze().cpu().numpy() * 255).astype(np.uint8)
#     gt_mask = (gt_mask.squeeze().cpu().numpy() * 255).astype(np.uint8)
#
#     concat = np.concatenate([
#         img,
#         np.stack([pred_mask]*3, axis=-1),
#         np.stack([gt_mask]*3, axis=-1)
#     ], axis=1)
#     Image.fromarray(concat).save(save_path)
#
# # ==============================
# # æµ‹è¯•å…¥å£
# # ==============================
# @torch.no_grad()
# def main():
#     import argparse
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--val_dir', type=str, default='/home/liuwei/mnt/instant_vggt_dataset/mask_train', help='éªŒè¯é›†è·¯å¾„')
#     parser.add_argument('--ckpt', type=str, required=True, help='æ¨¡å‹æƒé‡è·¯å¾„ (.safetensors)')
#     parser.add_argument('--save_dir', type=str, default='results')
#     parser.add_argument('--num_samples', type=int, default=10)
#     parser.add_argument('--img_height', type=int, default=256)
#     parser.add_argument('--img_width', type=int, default=496)
#     args = parser.parse_args()
#
#     device = 'cuda' if torch.cuda.is_available() else 'cpu'
#
#     # ==============================
#     # åŠ è½½æ•°æ®é›†
#     # ==============================
#     dataset = SkyDataset(
#         root_dir=args.val_dir,
#         split='val',
#     )
#     val_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)
#
#     # ==============================
#     # åŠ è½½æ¨¡å‹
#     # ==============================
#     model = Pi3().to(device)
#     print(f"ğŸ”¹ Loading safetensors checkpoint: {args.ckpt}")
#     ckpt = load_file(args.ckpt, device=device)  # âœ… ä½¿ç”¨ safetensors åŠ è½½
#     # safetensors æ–‡ä»¶ä¸€èˆ¬ç›´æ¥å­˜å‚¨ state_dictï¼Œæ— éœ€å† ckpt['model']
#     if "model" in ckpt:
#         ckpt = ckpt["model"]
#     model.load_state_dict(ckpt, strict=False)
#     model.eval()
#
#     # ==============================
#     # éšæœºé€‰10å¼ 
#     # ==============================
#     total_samples = len(dataset)
#     indices = random.sample(range(total_samples), args.num_samples)
#     print(f"Visualizing {args.num_samples} samples ...")
#
#     for i, idx in enumerate(tqdm(indices)):
#         ret = dataset[idx]
#         img = ret['image']
#         gt_mask = ret['depth']
#         img = img.unsqueeze(0).to(device)
#         img = img.unsqueeze(1).to(device)
#         gt_mask = gt_mask.to(device)
#
#         # å‰å‘æ¨ç†
#         pred = model(img, train_sky=True)
#         if isinstance(pred, dict) and 'sky' in pred:
#             pred_mask = pred['sky']
#         else:
#             pred_mask = pred
#         pred_mask = (pred_mask > 0.5).float()
#
#         save_path = os.path.join(args.save_dir, f'sample_{i:02d}.png')
#         visualize_results(img[0][0], pred_mask[0], gt_mask, save_path)
#
#     print(f"âœ… Results saved to {args.save_dir}")
#
# if __name__ == '__main__':
#     main()
#!/usr/bin/env python3
import os
import glob
import torch
import numpy as np
from PIL import Image
from safetensors.torch import load_file
from torchvision import transforms
from tqdm import tqdm
from pi3.models.pi3 import Pi3

# ==============================
# å¯è§†åŒ–ï¼ˆä½¿ç”¨åŸå›¾å°ºå¯¸ï¼‰
# ==============================
def visualize_results(orig_img, pred_mask, save_path):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    orig = np.array(orig_img)  # H,W,3 uint8
    pred_mask = (pred_mask.squeeze().cpu().numpy() * 255).astype(np.uint8)

    concat = np.concatenate([
        orig,
        np.stack([pred_mask]*3, axis=-1),
    ], axis=1)

    Image.fromarray(concat).save(save_path)

# ==============================
# å›¾ç‰‡è¯»å–å·¥å…·
# ==============================
def load_image(path, img_h, img_w):
    """è¿”å› transform åçš„å¼ é‡ + æœªç¼©æ”¾åŸå›¾ (PIL)"""
    orig_img = Image.open(path).convert("RGB")

    tf = transforms.Compose([
        transforms.Resize((img_h, img_w)),
        transforms.ToTensor()
    ])
    return tf(orig_img), orig_img   # è¿”å›ä¸¤ä»½

# ==============================
# ä¸»å‡½æ•°
# ==============================
@torch.no_grad()
def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--img_dir', type=str, required=True)
    parser.add_argument('--ckpt', type=str, required=True)
    parser.add_argument('--save_dir', type=str, default='results')
    parser.add_argument('--img_height', type=int, default=392)
    parser.add_argument('--img_width', type=int, default=392)
    args = parser.parse_args()

    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    img_list = sorted(glob.glob(os.path.join(args.img_dir, "*.*")))
    print(f"ğŸ”¹ Found {len(img_list)} images in {args.img_dir}")

    # ==============================
    # åŠ è½½æ¨¡å‹
    # ==============================
    model = Pi3().to(device)

    print(f"ğŸ”¹ Loading checkpoint: {args.ckpt}")
    ckpt = load_file(args.ckpt, device=device)
    if "model" in ckpt:
        ckpt = ckpt["model"]
    model.load_state_dict(ckpt, strict=False)
    model.eval()

    os.makedirs(args.save_dir, exist_ok=True)

    # ==============================
    # æ¨ç†
    # ==============================
    for path in tqdm(img_list):
        # åŠ è½½å›¾ç‰‡ï¼ˆç¼©æ”¾ç‰ˆ + åŸå›¾ï¼‰
        img_tensor, orig_img = load_image(path, args.img_height, args.img_width)
        H, W = orig_img.size[1], orig_img.size[0]  # PIL: (W, H)

        img_tensor = img_tensor.unsqueeze(0).to(device)
        img_tensor = img_tensor.unsqueeze(0).to(device)

        # æ¨¡å‹è¾“å‡º
        pred = model({"img": img_tensor}, train_sky=True)

        pred = pred["sky"] if isinstance(pred, dict) and "sky" in pred else pred
        pred = (pred > 0.5).float()

        # ==========================
        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šresize mask å›åŸå›¾å¤§å°
        # ==========================
        pred = pred[0][0]
        if pred.dim() == 4:
            pred_4d = pred
        elif pred.dim() == 3:
            if pred.shape[0] in [1, 3]:  # (C,H,W)
                pred_4d = pred.unsqueeze(0)
            else:  # (H,W,C)
                pred_4d = pred.permute(2, 0, 1).unsqueeze(0)
        elif pred.dim() == 2:  # (H,W)
            pred_4d = pred.unsqueeze(0).unsqueeze(0)
        else:
            raise ValueError(f"Unexpected pred dim: {pred.shape}")

        # è·å–åŸå›¾å°ºå¯¸
        H, W = orig_img.size[1], orig_img.size[0]

        # é‡æ–°æ’å€¼åˆ°åŸå›¾å¤§å°
        pred_resized = torch.nn.functional.interpolate(
            pred_4d, size=(H, W), mode="nearest"
        )

        # ä¿å­˜ maskï¼ˆå•ç‹¬ï¼‰
        mask_save_path = os.path.join(
            args.save_dir, f"{os.path.basename(path).split('.')[0]}.png"
        )
        Image.fromarray(
            (pred_resized.squeeze().cpu().numpy() * 255).astype(np.uint8)
        ).save(mask_save_path)

        # ä¿å­˜å¯è§†åŒ–å›¾
        viz_save_path = os.path.join(
            args.save_dir, f"{os.path.basename(path).split('.')[0]}_viz.png"
        )
        visualize_results(orig_img, pred_resized[0], viz_save_path)

    print(f"âœ… Done! Results saved to: {args.save_dir}")

if __name__ == '__main__':
    main()

