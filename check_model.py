import torch
from safetensors.torch import load_file
try:
    from pi3.models.pi3 import Pi3
except Exception as e:
    print("Warning: failed to import Pi3. Make sure your PYTHONPATH includes the project. Error:", e)
    Pi3 = None
# === 1ï¸âƒ£ é…ç½® ===
safetensor_path = "./ckpts/model.safetensors"  # âœ… ä¿®æ”¹æˆä½ çš„ safetensors æ–‡ä»¶è·¯å¾„
# from your_model_file import YourModelClass
# model = YourModelClass()  # âœ… æ›¿æ¢æˆä½ è‡ªå·±çš„æ¨¡å‹å®šä¹‰
model = Pi3()  # â† è¿™é‡Œå¡«å…¥ä½ çš„æ¨¡å‹å®ä¾‹

# === 2ï¸âƒ£ åŠ è½½æƒé‡ ===
print(f"\nğŸš€ Loading weights from: {safetensor_path}")
state_dict = load_file(safetensor_path)

missing, unexpected = model.load_state_dict(state_dict, strict=False)
print(f"âœ… Weights loaded. Missing keys: {len(missing)}, Unexpected keys: {len(unexpected)}")

if missing:
    print("âš ï¸ Missing keys:", missing[:10])
if unexpected:
    print("âš ï¸ Unexpected keys:", unexpected[:10])

# === 3ï¸âƒ£ æŸ¥çœ‹å‚æ•°ä¿¡æ¯ ===
print("\nğŸ” Model parameters overview:")
total_params = 0
trainable_params = 0
for name, param in model.named_parameters():
    numel = param.numel()
    total_params += numel
    if param.requires_grad:
        trainable_params += numel
    print(f"{name:<60} shape={tuple(param.shape)} requires_grad={param.requires_grad} params={numel}")

print(f"\nğŸ“Š Total parameters: {total_params:,}")
print(f"ğŸ§  Trainable parameters: {trainable_params:,}")
print(f"ğŸ§Š Frozen parameters: {total_params - trainable_params:,}\n")


# === 4ï¸âƒ£ å†»ç»“å±‚ç¤ºä¾‹ ===

# (1) å†»ç»“å…¨éƒ¨
# for p in model.parameters():
#     p.requires_grad = False

# (2) å†»ç»“éƒ¨åˆ†å±‚
for name, param in model.named_parameters():
    # æ¯”å¦‚å†»ç»“ encoderã€backboneã€æˆ–è€…ç‰¹å®šæ¨¡å—
    if name.startswith("encoder") or "backbone" in name:
        param.requires_grad = False

# æŸ¥çœ‹å†»ç»“ç»“æœ
print("\nğŸ”’ Frozen layers after selection:")
for name, param in model.named_parameters():
    if not param.requires_grad:
        print("  ", name)

# === 5ï¸âƒ£ æ‰“å°å†»ç»“ç»Ÿè®¡ ===
trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
frozen = sum(p.numel() for p in model.parameters() if not p.requires_grad)
print(f"\nâœ… Trainable: {trainable:,} | Frozen: {frozen:,} | Total: {trainable + frozen:,}")
